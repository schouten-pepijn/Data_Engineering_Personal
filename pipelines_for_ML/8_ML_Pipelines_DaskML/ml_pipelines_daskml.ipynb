{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Data Pipeline Workflow\n",
    "1. Data Sourcing\n",
    "2. Data Exploration\n",
    "3. Data Cleaning\n",
    "4. Data Wrangling\n",
    "5. Data Integration\n",
    "6. Feature Engineering\n",
    "7. Feature Selection\n",
    "8. Data Splitting\n",
    "9. Model Selection\n",
    "10. Model Training\n",
    "11. Model Evaluation\n",
    "12. Hyperparameter Tuning\n",
    "13. Final Testing\n",
    "14. Model Deployment\n",
    "15. Model Monitoring\n",
    "16. Model Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from dask_ml.preprocessing import (RobustScaler,\n",
    "                                   MinMaxScaler,\n",
    "                                   OneHotEncoder)\n",
    "from dask_ml.model_selection import (KFold,\n",
    "                                     train_test_split)\n",
    "from dask_ml.datasets import make_regression\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from statistics import mean\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DASK-ML Data Preprocessing (parallel scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0    1         2         3\n",
      "0 -0.538462  1.0 -0.842857 -0.733333\n",
      "1 -0.692308  0.0 -0.842857 -0.733333\n",
      "2 -0.846154  0.4 -0.871429 -0.733333\n",
      "3 -0.923077  0.2 -0.814286 -0.733333\n",
      "4 -0.615385  1.2 -0.842857 -0.733333\n",
      "          0         1         2         3\n",
      "0  0.222222  0.625000  0.067797  0.041667\n",
      "1  0.166667  0.416667  0.067797  0.041667\n",
      "2  0.111111  0.500000  0.050847  0.041667\n",
      "3  0.083333  0.458333  0.084746  0.041667\n",
      "4  0.194444  0.666667  0.067797  0.041667\n",
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "\n",
    "df = dd.from_array(X)\n",
    "\n",
    "# subtract the median, devide by the interquartile range \n",
    "r_scaler = (RobustScaler()\n",
    "            .fit_transform(df)\n",
    "            .compute())\n",
    "\n",
    "print(r_scaler.head())\n",
    "\n",
    "# Min-Max-Scaler [0, 1]\n",
    "mm_scaler = (MinMaxScaler()\n",
    "            .fit_transform(df)\n",
    "            .compute())\n",
    "\n",
    "print(mm_scaler.head()) \n",
    "\n",
    "# One Hot Encoder\n",
    "var_1 = da.from_array(\n",
    "    np.array(\n",
    "        [[\"Apples\"], [\"Melons\"], [\"Melons\"], [\"Oranges\"]]\n",
    "    ),\n",
    "    chunks=2\n",
    ")\n",
    "\n",
    "encoder = (OneHotEncoder(sparse_output=False)\n",
    "          .fit_transform(var_1)\n",
    "          .compute())\n",
    "\n",
    "print(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross Validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 40\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 10\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 40\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 10\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 40\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 10\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 40\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 10\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 40\n",
      "  p = blockwise(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/array/slicing.py:987: PerformanceWarning: Increasing number of chunks by factor of 10\n",
      "  p = blockwise(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train scores:  [0.9999970941045471, 0.9999974919985399, 0.9999976779775921, 0.9999983303663906, 0.9999974034370218]\n",
      "Test scores:  [0.9999972607168518, 0.9999973046581543, 0.999997626961904, 0.9999981517869371, 0.999997407355171]\n",
      "Mean train score:  0.9999975995768183\n",
      "Mean test score:  0.9999975502958036\n",
      "dask.array<concatenate, shape=(800, 10), dtype=float64, chunksize=(16, 10), chunktype=numpy.ndarray>\n",
      "[[-0.72778132  1.75358014 -1.63589511 -0.42851612  1.94106055  0.68488772\n",
      "   1.62225142 -0.1354828  -0.57206439 -1.22621463]\n",
      " [ 1.79248468  1.2641595   1.02104097  0.21974283 -0.23121309 -2.34420804\n",
      "   0.27449248  0.60585058 -1.16237758 -0.2244763 ]\n",
      " [ 0.55767448 -1.14652438  1.01880474  1.82038923 -0.03150098  0.02437674\n",
      "   0.48671356  0.51179773  0.35363546 -1.47521035]\n",
      " [-1.25521125  0.20963487  0.70151135  0.66632827  0.17211713  1.33436612\n",
      "   1.63551535 -0.23293505  0.00712698  0.23032439]\n",
      " [-0.34070806  1.06811311  0.29066025  0.35284983  0.16147256  0.02007247\n",
      "   1.18881733  0.95958015  0.92684038 -0.40866347]]\n"
     ]
    }
   ],
   "source": [
    "# create data\n",
    "X, y = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    random_state=87,\n",
    "    chunks=20\n",
    ")\n",
    "\n",
    "# create model\n",
    "model = LinearRegression()\n",
    "\n",
    "# create KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "# train loop\n",
    "train_scores: List[int] = []\n",
    "test_scores: List[int] = []\n",
    "\n",
    "for i, j in kf.split(X):\n",
    "    X_train, X_test = X[i], X[j]\n",
    "    y_train, y_test = y[i], y[j]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    train_scores.append(model.score(X_train, y_train))\n",
    "    test_scores.append(model.score(X_test, y_test))\n",
    "    \n",
    "print(\"Train scores: \", train_scores)\n",
    "print(\"Test scores: \", test_scores)\n",
    "print(\"Mean train score: \", mean(train_scores))\n",
    "print(\"Mean test score: \", mean(test_scores))\n",
    "\n",
    "# splitting dask arrays\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2\n",
    ")\n",
    "print(X_train)\n",
    "print(X_train.compute()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter Tuning with DASK-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_ml.datasets import make_classification\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scipy.stats import uniform, loguniform\n",
    "from dask_ml.model_selection import HyperbandSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 51710 instead\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/data_eng/lib/python3.12/site-packages/dask/base.py:1541: UserWarning: Running on a single-machine scheduler when a distributed client is active might lead to unexpected results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.8744844070862653, 'l1_ratio': 0.09783217731538718}\n",
      "0.75\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# start client\n",
    "client = Client(processes=False)\n",
    "\n",
    "# create data\n",
    "X, y = make_classification(\n",
    "    chunks=20,\n",
    "    random_state=87\n",
    ")\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# create classifier model\n",
    "clf = SGDClassifier(\n",
    "    tol=1e-3,\n",
    "    penalty=\"elasticnet\",\n",
    "    random_state=87\n",
    ")\n",
    "\n",
    "# create parameter grid\n",
    "params = {\n",
    "    \"alpha\": loguniform(1e-2, 1e0),\n",
    "    \"l1_ratio\": uniform(0.0, 1.0)\n",
    "}\n",
    "\n",
    "# create hyperparameter search\n",
    "search = HyperbandSearchCV(\n",
    "    clf,\n",
    "    params,\n",
    "    max_iter=80,\n",
    "    random_state=87\n",
    ")\n",
    "\n",
    "# fit the search\n",
    "search.fit(X_train, y_train,\n",
    "           classes=[0, 1])\n",
    "\n",
    "print(search.best_params_)\n",
    "print(search.best_score_)\n",
    "\n",
    "# perform evaluation\n",
    "print(search.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical Imputation with DASK-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from dask_ml.preprocessing import OneHotEncoder\n",
    "from dask_ml.impute import SimpleImputer\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    color  weight  taste   fruit\n",
      "0     red   150.0  sweet   apple\n",
      "1  orange   180.0  sweet  orange\n",
      "2   green   200.0   sour   apple\n",
      "3    <NA>   160.0  sweet   apple\n",
      "4  yellow     NaN  sweet  orange\n",
      "5   green   220.0   sour   melon\n",
      "    color\n",
      "0     red\n",
      "1  orange\n",
      "2   green\n",
      "3   green\n",
      "4  yellow\n",
      "5   green\n",
      "   weight\n",
      "0   150.0\n",
      "1   180.0\n",
      "2   200.0\n",
      "3   160.0\n",
      "4   180.0\n",
      "5   220.0\n"
     ]
    }
   ],
   "source": [
    "# create data\n",
    "data = {\n",
    "    'color':\n",
    "        ['red', 'orange', 'green', None, 'yellow', 'green'],\n",
    "    'weight':\n",
    "        [150, 180, 200, 160, None, 220],\n",
    "    'taste':\n",
    "        ['sweet', 'sweet', 'sour', 'sweet', 'sweet', 'sour'],\n",
    "    'fruit':\n",
    "        ['apple', 'orange', 'apple', 'apple', 'orange', 'melon']\n",
    "}\n",
    "\n",
    "df = dd.from_pandas(\n",
    "    pd.DataFrame(data),\n",
    "    npartitions=2\n",
    ")\n",
    "print(df.compute())\n",
    "\n",
    "ddf = df.copy()\n",
    "\n",
    "# imputer for colors\n",
    "imputer_1 = SimpleImputer(\n",
    "    strategy=\"most_frequent\"\n",
    ")\n",
    "\n",
    "df_fit = imputer_1.fit(df)\n",
    "color = imputer_1.transform(df[[\"color\"]])\n",
    "\n",
    "# execute\n",
    "print(color.compute())\n",
    "\n",
    "\n",
    "# imputer for weights\n",
    "imputer_2 = SimpleImputer(\n",
    "    strategy=\"mean\"\n",
    ")\n",
    "\n",
    "weight = df_fit.fit_transform(df[[\"weight\"]])\n",
    "\n",
    "# execute\n",
    "print(weight.compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression with DASK-ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dask_ml.linear_model import LinearRegression\n",
    "from dask_ml.datasets import make_regression\n",
    "from dask_ml.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score: 0.5660094720589386\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'max_iter': 100, 'multi_class': 'ovr', 'n_jobs': 1, 'penalty': 'l2', 'random_state': None, 'solver': 'admm', 'solver_kwargs': None, 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "num_samples = 100\n",
    "num_features = 4\n",
    "\n",
    "# create data\n",
    "X, y = make_regression(\n",
    "    n_samples=num_samples,\n",
    "    n_features=num_features,\n",
    "    noise=0.1,\n",
    "    chunks=4\n",
    ")\n",
    "\n",
    "y = np.exp(y / 200).astype(int)\n",
    "\n",
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "# create and train model\n",
    "model = LinearRegression()\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train)\n",
    "\n",
    "# score model on test set\n",
    "score = model.score(\n",
    "    X_test,\n",
    "    y_test)\n",
    "\n",
    "print(f\"Model score: {score}\")\n",
    "\n",
    "print(model.get_params())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
